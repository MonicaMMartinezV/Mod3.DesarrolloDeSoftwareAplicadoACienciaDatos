{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a81c2f",
   "metadata": {},
   "source": [
    "# TC 3006B Inteligencia artificial avanzada para la ciencia de datos I \n",
    "# CIFAR-10 Data Preparation (PyTorch)\n",
    "## Feedback\n",
    "\n",
    "## Deep Learning -- Data Cleaning \n",
    "\n",
    "### Objective: Load CIFAR-10, explore data, compute per-channel statistics (mean & std), normalize images, and verify normalization. \n",
    "\n",
    "### Instructions\n",
    "- Focus on data preparation, analysis, data is not usually as nice as CIFAR10 is. Model training follows as explained in classes.\n",
    "- Write comments and reflections in the indicated, verify you answer questions in Markdown cells.\n",
    "- Keep your code clean, reproducible, and well‑commented.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37f400",
   "metadata": {},
   "source": [
    "\n",
    "## Environment & Reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec560c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries as needed, if using Colab, maybe all good\n",
    "\n",
    "import os, json, random, math, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##########################################\n",
    "SEED = 42 #for reproducibility \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "###########################################\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aef7ec",
   "metadata": {},
   "source": [
    "\n",
    "## Download & Load CIFAR-10 (Train/Test Splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f4328-5eda-43f8-bc2e-8b64c764c5e0",
   "metadata": {},
   "source": [
    "#### If using Colab you may need the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990752e5-2223-40cf-8b27-2bd8daa504d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75467c44-6614-4d76-b897-5279377755f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/Your Path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1871d2f-bb34-4fe7-b3b2-51da185c2a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f40a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe obvious, adjust path according to your needs\n",
    "DATA_DIR = Path(\"/media/pepe/DataUbuntu/Databases/cifar-10\") \n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Base transform for statistics: convert to tensor only (no normalization/augmentations yet)\n",
    "base_transform = transforms.ToTensor()\n",
    "\n",
    "train_set = datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=base_transform)\n",
    "test_set  = datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=base_transform)\n",
    "\n",
    "len(train_set), len(test_set), train_set.data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc4311",
   "metadata": {},
   "source": [
    "\n",
    "### Explore de dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_set.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea442996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(dataset, n=5):\n",
    "    fig, axes = plt.subplots(1, n, figsize=(n*2.5, 2.5))\n",
    "    for ax in axes:\n",
    "        idx = np.random.randint(0, len(dataset))\n",
    "        img, label = dataset[idx]\n",
    "        # img: tensor [C,H,W] in [0,1]\n",
    "        ax.imshow(np.transpose(img.numpy(), (1, 2, 0)))  # HWC\n",
    "        ax.set_title(classes[label])\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(train_set, n=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494ccc6",
   "metadata": {},
   "source": [
    "\n",
    "> **Reflection (Markdown):** Describe CIFAR‑10 (resolution, channels, number of classes/samples). Include one sentence on why normalization is helpful for training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e4294",
   "metadata": {},
   "source": [
    "\n",
    "## Compute Per‑Channel Mean & Standard Deviation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09960dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "'''\n",
    "Compute mean and std, before normalization\n",
    "\n",
    "'''\n",
    "\n",
    "mean, std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6a3d1",
   "metadata": {},
   "source": [
    "\n",
    "> Record your computed values here (e.g., `Mean ≈ [0.4914, 0.4822, 0.4465]`, `Std ≈ [0.2470, 0.2435, 0.2616]`). Your numbers should closely match these canonical references.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b638be5c",
   "metadata": {},
   "source": [
    "\n",
    "## Normalize Datasets Using Computed Stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=mean.tolist(), std=std.tolist())\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "train_set_norm = datasets.CIFAR10(root=DATA_DIR, train=True, download=False, transform=train_transform)\n",
    "test_set_norm  = datasets.CIFAR10(root=DATA_DIR, train=False, download=False, transform=test_transform)\n",
    "\n",
    "len(train_set_norm), len(test_set_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa5466",
   "metadata": {},
   "source": [
    "\n",
    "## Verify Normalization (Means ≈ 0, Stds ≈ 1)\n",
    "\n",
    "Confirm the transformation worked as intended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader_norm = DataLoader(train_set_norm, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "'''\n",
    "Verify that data are normalized\n",
    "'''\n",
    "\n",
    "mean_norm, std_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfc6c9",
   "metadata": {},
   "source": [
    "\n",
    "> Report the post‑normalization means and stds. They should be close to `[0,0,0]` and `[1,1,1]` (small deviations are normal due to rounding/batching).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa1b48",
   "metadata": {},
   "source": [
    "\n",
    "## Light Data Augmentation\n",
    "Add a few basic augmentations (random crop with padding, random horizontal flip). Use **train** only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcfe8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #anything else you may want to add is welcomed\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "train_set_aug = datasets.CIFAR10(root=DATA_DIR, train=True, download=False, transform=aug_transform)\n",
    "len(train_set_aug)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075f932c",
   "metadata": {},
   "source": [
    "\n",
    "> Explain when/why augmentation helps. What risks do heavy augmentations pose for small images like CIFAR‑10 (32×32)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a667e6ee",
   "metadata": {},
   "source": [
    "\n",
    "## Class Distribution\n",
    "Confirm class balance. CIFAR‑10 should be balanced across the 10 classes. Create a plot as a visual aid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a66123",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cifar10 is perfectly distributed among classes, this will not always be the case, plots help, numbers help\n",
    "'''\n",
    "\n",
    "# show class distribution\n",
    "# show plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc34e8",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Submission Checklist\n",
    "- [ ] Printed dataset sizes and showed random sample images.\n",
    "- [ ] Reported per‑channel mean & std from the training set.\n",
    "- [ ] Applied normalization using computed stats.\n",
    "- [ ] Verified post‑normalization mean/std are ~0/1.\n",
    "- [ ] Basic augmentations and rationale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e60b32-4d22-41d8-93cf-801cd2a3cb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6e822-aaaf-4a07-ad0d-a15a5b5aaadd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
